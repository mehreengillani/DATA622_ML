<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mehreen Ali Gillani">
<meta name="dcterms.date" content="2024-06-10">

<title>Assignment 1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="Assignment1_Mehreen_files/libs/clipboard/clipboard.min.js"></script>
<script src="Assignment1_Mehreen_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="Assignment1_Mehreen_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="Assignment1_Mehreen_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="Assignment1_Mehreen_files/libs/quarto-html/popper.min.js"></script>
<script src="Assignment1_Mehreen_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Assignment1_Mehreen_files/libs/quarto-html/anchor.min.js"></script>
<link href="Assignment1_Mehreen_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Assignment1_Mehreen_files/libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Assignment1_Mehreen_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Assignment1_Mehreen_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Assignment1_Mehreen_files/libs/bootstrap/bootstrap-d6a003b94517c951b2d65075d42fb01b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="fullcontent quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Assignment 1</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Mehreen Ali Gillani </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 10, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="question-1" class="level2">
<h2 class="anchored" data-anchor-id="question-1">Question 1</h2>
<p>Consider the following data set: The data set Auto, which is part of the ISLR package, contains information on various characteristics of different makes and models of automobiles.</p>
<div id="5465efbe" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">#!pip install nbformat</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nbformat</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nbclient <span class="im">import</span> NotebookClient</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">#import ISLP</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ISLP <span class="im">import</span> load_data</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> load_data(<span class="st">"Auto"</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>data.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mpg</th>
<th data-quarto-table-cell-role="th">cylinders</th>
<th data-quarto-table-cell-role="th">displacement</th>
<th data-quarto-table-cell-role="th">horsepower</th>
<th data-quarto-table-cell-role="th">weight</th>
<th data-quarto-table-cell-role="th">acceleration</th>
<th data-quarto-table-cell-role="th">year</th>
<th data-quarto-table-cell-role="th">origin</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">name</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">chevrolet chevelle malibu</th>
<td>18.0</td>
<td>8</td>
<td>307.0</td>
<td>130</td>
<td>3504</td>
<td>12.0</td>
<td>70</td>
<td>1</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">buick skylark 320</th>
<td>15.0</td>
<td>8</td>
<td>350.0</td>
<td>165</td>
<td>3693</td>
<td>11.5</td>
<td>70</td>
<td>1</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">plymouth satellite</th>
<td>18.0</td>
<td>8</td>
<td>318.0</td>
<td>150</td>
<td>3436</td>
<td>11.0</td>
<td>70</td>
<td>1</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">amc rebel sst</th>
<td>16.0</td>
<td>8</td>
<td>304.0</td>
<td>150</td>
<td>3433</td>
<td>12.0</td>
<td>70</td>
<td>1</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">ford torino</th>
<td>17.0</td>
<td>8</td>
<td>302.0</td>
<td>140</td>
<td>3449</td>
<td>10.5</td>
<td>70</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Remove missing values.</p>
<div id="4733bd68" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for missing values</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Missing values before removal:"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data.isnull().<span class="bu">sum</span>())</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove rows with any missing values</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>data_clean <span class="op">=</span> data.dropna()</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Check shape after removal</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Original shape: </span><span class="sc">{</span>data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cleaned shape: </span><span class="sc">{</span>data_clean<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Rows removed: </span><span class="sc">{</span><span class="bu">len</span>(data) <span class="op">-</span> <span class="bu">len</span>(data_clean)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Missing values before removal:
mpg             0
cylinders       0
displacement    0
horsepower      0
weight          0
acceleration    0
year            0
origin          0
dtype: int64

Original shape: (392, 8)
Cleaned shape: (392, 8)
Rows removed: 0</code></pre>
</div>
</div>
<ol type="a">
<li>Which of the predictors are quantitative, and which are qualitative?</li>
</ol>
<div id="486eeede" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify quantitative and qualitative predictors</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>quantitative_predictors <span class="op">=</span> data_clean.select_dtypes(include<span class="op">=</span>[<span class="st">'number'</span>]).columns.tolist()</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>qualitative_predictors <span class="op">=</span> data_clean.select_dtypes(include<span class="op">=</span>[<span class="st">'object'</span>, <span class="st">'category'</span>]).columns.tolist()  </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Quantitative Predictors:"</span>, quantitative_predictors)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Qualitative Predictors:"</span>, qualitative_predictors)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Quantitative Predictors: ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin']
Qualitative Predictors: []</code></pre>
</div>
</div>
<p>Find continous and categorical variables among the predictors.</p>
<p>find nunique for year and origin</p>
<div id="624fdcc1" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>nunique_values <span class="op">=</span> data_clean.nunique()</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(nunique_values)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>mpg             127
cylinders         5
displacement     81
horsepower       93
weight          346
acceleration     95
year             13
origin            3
dtype: int64</code></pre>
</div>
</div>
<p>Name is the only qualitative predictor, while the rest are quantitative predictors.</p>
<ol type="1">
<li>cylinders has 5 unique values, so it can be considered categorical.</li>
<li>Year has 13 unique values so it will be considered ordinal.</li>
<li>Origin has 3 unique values, making it categorical. Rest all are continuous variables.</li>
</ol>
<!-- -->
<ol start="2" type="a">
<li>What is the range of each quantitative predictor? You can answer this using the min() and max() methods in numpy.</li>
</ol>
<div id="53869611" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> quantitative_predictors:</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    col_min <span class="op">=</span> data_clean[col].<span class="bu">min</span>()</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    col_max <span class="op">=</span> data_clean[col].<span class="bu">max</span>()</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">: Min = </span><span class="sc">{</span>col_min<span class="sc">}</span><span class="ss">, Max = </span><span class="sc">{</span>col_max<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>mpg: Min = 9.0, Max = 46.6
cylinders: Min = 3, Max = 8
displacement: Min = 68.0, Max = 455.0
horsepower: Min = 46, Max = 230
weight: Min = 1613, Max = 5140
acceleration: Min = 8.0, Max = 24.8
year: Min = 70, Max = 82
origin: Min = 1, Max = 3</code></pre>
</div>
</div>
<ol start="3" type="a">
<li>What is the mean and standard deviation of each quantitative predictor?</li>
</ol>
<div id="acc932f1" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> quantitative_predictors:</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    col_mean <span class="op">=</span> data_clean[col].mean()</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    col_std <span class="op">=</span> data_clean[col].std()</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">: Mean = </span><span class="sc">{</span>col_mean<span class="sc">}</span><span class="ss">, Std Dev = </span><span class="sc">{</span>col_std<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>mpg: Mean = 23.445918367346938, Std Dev = 7.8050074865717995
cylinders: Mean = 5.471938775510204, Std Dev = 1.7057832474527845
displacement: Mean = 194.41198979591837, Std Dev = 104.64400390890466
horsepower: Mean = 104.46938775510205, Std Dev = 38.49115993282849
weight: Mean = 2977.5841836734694, Std Dev = 849.4025600429492
acceleration: Mean = 15.541326530612244, Std Dev = 2.758864119188082
year: Mean = 75.9795918367347, Std Dev = 3.6837365435778295
origin: Mean = 1.5765306122448979, Std Dev = 0.8055181834183056</code></pre>
</div>
</div>
<ol start="4" type="a">
<li>Now remove the 10th through 85th observations. What is the mean and standard deviation of each quantitative predictor in the subset of the data that remains?</li>
</ol>
<div id="1ce350c7" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>data_subset <span class="op">=</span> data_clean.drop(data_clean.index[<span class="dv">9</span>:<span class="dv">85</span>])</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> quantitative_predictors:</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    col_mean <span class="op">=</span> data_subset[col].mean()</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    col_std <span class="op">=</span> data_subset[col].std()</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss"> (Subset): Mean = </span><span class="sc">{</span>col_mean<span class="sc">}</span><span class="ss">, Std Dev = </span><span class="sc">{</span>col_std<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>mpg (Subset): Mean = 25.04163701067616, Std Dev = 7.91287442060972
cylinders (Subset): Mean = 5.274021352313167, Std Dev = 1.6321549688677217
displacement (Subset): Mean = 179.37366548042704, Std Dev = 95.51289675679097
horsepower (Subset): Mean = 98.7153024911032, Std Dev = 33.8227113152057
weight (Subset): Mean = 2881.505338078292, Std Dev = 792.5484938790652
acceleration (Subset): Mean = 15.73879003558719, Std Dev = 2.5701912023177935
year (Subset): Mean = 77.50889679715303, Std Dev = 2.9894025669301008
origin (Subset): Mean = 1.6334519572953736, Std Dev = 0.8307603049561275</code></pre>
</div>
</div>
<ol start="5" type="a">
<li>Using the full data set, investigate the predictors graphically, using scatterplots or other tools of your choice. Create some plots highlighting the relationships among the predictors. Comment on your findings</li>
</ol>
<div id="d7db221a" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns   </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the pairplot object</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Select only important predictors</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>key_predictors <span class="op">=</span> [<span class="st">'mpg'</span>, <span class="st">'weight'</span>, <span class="st">'horsepower'</span>, <span class="st">'year'</span>, <span class="st">'displacement'</span>]</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>sns.pairplot(data_clean[key_predictors], height<span class="op">=</span><span class="fl">1.5</span>,  <span class="co"># Smaller height per subplot</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>             aspect<span class="op">=</span><span class="dv">1</span>) </span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Pairplot of Key Predictors"</span>, y<span class="op">=</span><span class="fl">1.02</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation heatmap</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>correlation_matrix <span class="op">=</span> data_clean[quantitative_predictors].corr()</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>sns.heatmap(correlation_matrix, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">'coolwarm'</span>, fmt<span class="op">=</span><span class="st">".2f"</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Correlation Heatmap of Quantitative Predictors"</span>)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Assignment1_Mehreen_files/figure-html/cell-9-output-1.png" width="710" height="739" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Assignment1_Mehreen_files/figure-html/cell-9-output-2.png" width="830" height="730" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="correlation-analysis-summary" class="level3">
<h3 class="anchored" data-anchor-id="correlation-analysis-summary">Correlation Analysis Summary</h3>
<section id="target-variable-mpg-fuel-efficiency" class="level4">
<h4 class="anchored" data-anchor-id="target-variable-mpg-fuel-efficiency">Target Variable: MPG (Fuel Efficiency)</h4>
<p>Strong Negative Correlations:</p>
<p>MPG decreases significantly with higher values of:</p>
<ul>
<li><p>Cylinders (-0.78)</p></li>
<li><p>Displacement (-0.81)</p></li>
<li><p>Horsepower (-0.78)</p></li>
<li><p>Weight (-0.83)</p></li>
</ul>
<p>Positive Correlations: MPG improves with:</p>
<ul>
<li><p>Model year (+0.58) - newer cars are more fuel efficient</p></li>
<li><p>Acceleration (+0.42) - faster acceleration correlates with better MPG</p></li>
<li><p>Origin (+0.57) - specific origin cars tend to be more fuel efficient</p>
<h4 id="engine-characteristics-cylinders-displacement-strong-positive-relationships" class="anchored">Engine Characteristics (Cylinders &amp; Displacement) Strong Positive Relationships:</h4></li>
<li><p>Cylinders ↔︎ Displacement (+0.95)</p></li>
<li><p>Cylinders ↔︎ Horsepower (+0.84)</p></li>
<li><p>Displacement ↔︎ Horsepower (+0.90)</p></li>
<li><p>All three show strong positive correlation with Weight (+0.90+)</p></li>
</ul>
</section>
<section id="negative-trends-over-time" class="level4">
<h4 class="anchored" data-anchor-id="negative-trends-over-time">Negative Trends Over Time:</h4>
<ul>
<li><p>Cylinders negatively correlate with Year (-0.35) - newer cars have fewer cylinders</p></li>
<li><p>Displacement negatively correlates with Year (-0.37) - engine sizes decreasing over time</p></li>
<li><p>Both show negative correlation with Origin (-0.57) - specific origin cars favor smaller engines#Weight Relationships</p></li>
</ul>
</section>
<section id="weight-increases-with" class="level4">
<h4 class="anchored" data-anchor-id="weight-increases-with">Weight increases with:</h4>
<ul>
<li><p>Engine size (Cylinders, Displacement, Horsepower) Weight decreases with:</p></li>
<li><p>Model Year (-0.31) - newer cars are lighter</p></li>
<li><p>Origin (-0.59) - non-American cars are lighter</p></li>
<li><p>Acceleration (-0.42) - lighter cars accelerate faster</p>
<h4 id="acceleration-shows-moderate-positive-correlation-with" class="anchored">Acceleration shows moderate positive correlation with:</h4></li>
<li><p>Model Year (+0.29) - newer cars accelerate better</p></li>
<li><p>Origin (+0.21) - non-American cars have better acceleration</p></li>
<li><p>Weakest correlations observed with Acceleration, suggesting it’s influenced by multiple factors beyond engine specs alone</p></li>
</ul>
<ol start="6" type="a">
<li>Suppose that we wish to predict gas mileage (mpg) on the basis of the other variables. Do your plots suggest that any of the other variables might be useful in predicting mpg? Justify your answer. Yes, the plots and correlation analysis suggest that several variables could be useful in predicting gas mileage (mpg). Specifically:</li>
</ol>
<!-- -->
<ol type="1">
<li>Cylinders: Strong negative correlation with mpg (-0.78) indicates that cars with more cylinders tend to have lower fuel efficiency.</li>
<li>Displacement: Also shows a strong negative correlation with mpg (-0.81), suggesting that larger engine sizes are associated with lower gas mileage.</li>
<li>Horsepower: With a strong negative correlation (-0.78), higher horsepower engines tend to consume more fuel, leading to lower mpg.</li>
<li>Weight: The strongest negative correlation with mpg (-0.83) indicates that heavier cars generally have lower fuel efficiency.</li>
<li>Model Year: A positive correlation (+0.58) suggests that newer cars are more fuel efficient, likely due to advancements in technology and design.</li>
<li>Acceleration: A moderate positive correlation (+0.42) indicates that cars with better acceleration may also have better fuel efficiency.</li>
<li>Origin: The positive correlation (+0.57) suggests that cars from certain origins tend to be more fuel efficient. Overall, the strong correlations of cylinders, displacement, horsepower, and weight with mpg indicate that these variables are likely to be significant predictors of gas mileage. Additionally, model year, acceleration, and origin also show meaningful relationships with mpg that could enhance predictive models.</li>
</ol>
<div id="be4d7c60" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear Regression Analysis for MPG Prediction</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, r2_score, mean_absolute_error</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Select numeric columns</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>numeric_cols <span class="op">=</span> data_clean.select_dtypes(include<span class="op">=</span>[<span class="st">'number'</span>]).columns.tolist()</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Numeric columns:"</span>, numeric_cols)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove 'mpg' from predictors</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">'mpg'</span> <span class="kw">in</span> numeric_cols:</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    numeric_cols.remove(<span class="st">'mpg'</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data_clean[numeric_cols]</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data_clean[<span class="st">'mpg'</span>]</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Using </span><span class="sc">{</span><span class="bu">len</span>(numeric_cols)<span class="sc">}</span><span class="ss"> numeric predictors:"</span>)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(numeric_cols)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Train-test split</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, shuffle<span class="op">=</span><span class="va">True</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Train model</span></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train)</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions</span></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate residuals (ADD THIS LINE!)</span></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> y_test <span class="op">-</span> y_pred</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Metrics</span></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> np.sqrt(mse)</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>mae <span class="op">=</span> mean_absolute_error(y_test, y_pred)</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>r2 <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MODEL PERFORMANCE EVALUATION"</span>)</span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean Squared Error (MSE): </span><span class="sc">{</span>mse<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Root Mean Squared Error (RMSE): </span><span class="sc">{</span>rmse<span class="sc">:.2f}</span><span class="ss"> MPG"</span>)</span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean Absolute Error (MAE): </span><span class="sc">{</span>mae<span class="sc">:.2f}</span><span class="ss"> MPG"</span>)</span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R-squared (R²): </span><span class="sc">{</span>r2<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Adjusted R²: </span><span class="sc">{</span><span class="dv">1</span> <span class="op">-</span> (<span class="dv">1</span><span class="op">-</span>r2)<span class="op">*</span>(<span class="bu">len</span>(y_test)<span class="op">-</span><span class="dv">1</span>)<span class="op">/</span>(<span class="bu">len</span>(y_test)<span class="op">-</span>X.shape[<span class="dv">1</span>]<span class="op">-</span><span class="dv">1</span>)<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare to baseline</span></span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a>baseline_pred <span class="op">=</span> np.full_like(y_test, y_train.mean())</span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a>baseline_mse <span class="op">=</span> mean_squared_error(y_test, baseline_pred)</span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Baseline (predict mean): MSE = </span><span class="sc">{</span>baseline_mse<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Improvement over baseline: </span><span class="sc">{</span>(<span class="dv">1</span> <span class="op">-</span> mse<span class="op">/</span>baseline_mse)<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%"</span>)</span>
<span id="cb15-57"><a href="#cb15-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-58"><a href="#cb15-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Residual statistics</span></span>
<span id="cb15-59"><a href="#cb15-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Residual Statistics:"</span>)</span>
<span id="cb15-60"><a href="#cb15-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean residual: </span><span class="sc">{</span>residuals<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb15-61"><a href="#cb15-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Std of residuals: </span><span class="sc">{</span>residuals<span class="sc">.</span>std()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb15-62"><a href="#cb15-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max residual: </span><span class="sc">{</span>residuals<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb15-63"><a href="#cb15-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Min residual: </span><span class="sc">{</span>residuals<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb15-64"><a href="#cb15-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-65"><a href="#cb15-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization</span></span>
<span id="cb15-66"><a href="#cb15-66" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb15-67"><a href="#cb15-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-68"><a href="#cb15-68" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Actual vs Predicted</span></span>
<span id="cb15-69"><a href="#cb15-69" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].scatter(y_test, y_pred, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb15-70"><a href="#cb15-70" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].plot([y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], [y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], </span>
<span id="cb15-71"><a href="#cb15-71" aria-hidden="true" tabindex="-1"></a>                <span class="st">'r--'</span>, lw<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb15-72"><a href="#cb15-72" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_xlabel(<span class="st">'Actual MPG'</span>)</span>
<span id="cb15-73"><a href="#cb15-73" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_ylabel(<span class="st">'Predicted MPG'</span>)</span>
<span id="cb15-74"><a href="#cb15-74" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="ss">f'Actual vs Predicted (R² = </span><span class="sc">{</span>r2<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb15-75"><a href="#cb15-75" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb15-76"><a href="#cb15-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-77"><a href="#cb15-77" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Residuals vs Predicted</span></span>
<span id="cb15-78"><a href="#cb15-78" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].scatter(y_pred, residuals, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb15-79"><a href="#cb15-79" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].axhline(y<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, lw<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb15-80"><a href="#cb15-80" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_xlabel(<span class="st">'Predicted MPG'</span>)</span>
<span id="cb15-81"><a href="#cb15-81" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_ylabel(<span class="st">'Residuals'</span>)</span>
<span id="cb15-82"><a href="#cb15-82" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'Residuals vs Predicted'</span>)</span>
<span id="cb15-83"><a href="#cb15-83" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb15-84"><a href="#cb15-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-85"><a href="#cb15-85" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Distribution of residuals</span></span>
<span id="cb15-86"><a href="#cb15-86" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].hist(residuals, bins<span class="op">=</span><span class="dv">20</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb15-87"><a href="#cb15-87" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].axvline(x<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, lw<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb15-88"><a href="#cb15-88" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_xlabel(<span class="st">'Residuals'</span>)</span>
<span id="cb15-89"><a href="#cb15-89" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb15-90"><a href="#cb15-90" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_title(<span class="st">'Distribution of Residuals'</span>)</span>
<span id="cb15-91"><a href="#cb15-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-92"><a href="#cb15-92" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Q-Q plot for normality</span></span>
<span id="cb15-93"><a href="#cb15-93" aria-hidden="true" tabindex="-1"></a>stats.probplot(residuals, dist<span class="op">=</span><span class="st">"norm"</span>, plot<span class="op">=</span>axes[<span class="dv">1</span>, <span class="dv">1</span>])</span>
<span id="cb15-94"><a href="#cb15-94" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_title(<span class="st">'Q-Q Plot for Normality Check'</span>)</span>
<span id="cb15-95"><a href="#cb15-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-96"><a href="#cb15-96" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb15-97"><a href="#cb15-97" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb15-98"><a href="#cb15-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-99"><a href="#cb15-99" aria-hidden="true" tabindex="-1"></a><span class="co"># Additional: Show feature coefficients</span></span>
<span id="cb15-100"><a href="#cb15-100" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb15-101"><a href="#cb15-101" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"FEATURE COEFFICIENTS"</span>)</span>
<span id="cb15-102"><a href="#cb15-102" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb15-103"><a href="#cb15-103" aria-hidden="true" tabindex="-1"></a>coefficients <span class="op">=</span> pd.DataFrame({</span>
<span id="cb15-104"><a href="#cb15-104" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X.columns,</span>
<span id="cb15-105"><a href="#cb15-105" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Coefficient'</span>: model.coef_,</span>
<span id="cb15-106"><a href="#cb15-106" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Abs_Effect'</span>: np.<span class="bu">abs</span>(model.coef_)</span>
<span id="cb15-107"><a href="#cb15-107" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb15-108"><a href="#cb15-108" aria-hidden="true" tabindex="-1"></a>coefficients <span class="op">=</span> coefficients.sort_values(<span class="st">'Abs_Effect'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb15-109"><a href="#cb15-109" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coefficients)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Numeric columns: ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin']

Using 7 numeric predictors:
['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin']
==================================================
MODEL PERFORMANCE EVALUATION
==================================================
Mean Squared Error (MSE): 10.71
Root Mean Squared Error (RMSE): 3.27 MPG
Mean Absolute Error (MAE): 2.42 MPG
R-squared (R²): 0.79
Adjusted R²: 0.77

Baseline (predict mean): MSE = 51.62
Improvement over baseline: 79.3%

Residual Statistics:
Mean residual: -0.27
Std of residuals: 3.28
Max residual: 9.49
Min residual: -9.96</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Assignment1_Mehreen_files/figure-html/cell-10-output-2.png" width="758" height="566" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
==================================================
FEATURE COEFFICIENTS
==================================================
        Feature  Coefficient  Abs_Effect
6        origin     1.613457    1.613457
5          year     0.767743    0.767743
0     cylinders    -0.345789    0.345789
4  acceleration     0.037950    0.037950
2    horsepower    -0.021302    0.021302
1  displacement     0.015109    0.015109
3        weight    -0.006142    0.006142</code></pre>
</div>
</div>
<p>Findings: . The high R² of 0.79 confirms these variables collectively explain most MPG variation. The negative coefficients for weight/horsepower and positive for year align with our correlation analysis. . The MSE of 10.71 (RMSE ≈ 3.27) means our predictions are typically within 3-4 MPG of actual values, which is quite good for automotive fuel economy prediction.</p>
<p>Part 2 ## Question 2 a) Download and load the training and test data sets using pandas. Make sure to load all of the data (there is no header) The zeroth column corresponds to the class label, a digit from 0-9, and the columns 1 to 256 correspond to a grayscale value from -1 to 1. Select the first entry in the training set, resize it to 16x16, and plot the image (you can use plt.imshow()).</p>
<div id="40c207c1" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>df_train <span class="op">=</span> pd.read_csv(<span class="st">"https://raw.githubusercontent.com/georgehagstrom/DATA622Spring2026/refs/heads/main/website/assignments/labs/labData/zip.train"</span>, header<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>df_test <span class="op">=</span> pd.read_csv(<span class="st">"https://raw.githubusercontent.com/georgehagstrom/DATA622Spring2026/refs/heads/main/website/assignments/labs/labData/zip.test"</span>, header<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_train.head())  <span class="co"># Show first 5 rows</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Columns:"</span>, df_train.columns.tolist())</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Split space-separated strings into columns</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>df_train <span class="op">=</span> df_train[<span class="dv">0</span>].<span class="bu">str</span>.split(expand<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>df_test <span class="op">=</span> df_test[<span class="dv">0</span>].<span class="bu">str</span>.split(expand<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. CONVERT TO NUMERIC</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>df_train <span class="op">=</span> df_train.astype(<span class="bu">float</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>df_test <span class="op">=</span> df_test.astype(<span class="bu">float</span>)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. EXTRACT FEATURES AND LABELS</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> df_train.iloc[:, <span class="dv">0</span>].astype(<span class="bu">int</span>)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> df_train.iloc[:, <span class="dv">1</span>:<span class="dv">257</span>]</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> df_test.iloc[:, <span class="dv">0</span>].astype(<span class="bu">int</span>)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> df_test.iloc[:, <span class="dv">1</span>:<span class="dv">257</span>]</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples, </span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> features"</span>)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples, </span><span class="sc">{</span>X_test<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> features"</span>)</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. VISUALIZE FIRST IMAGE</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>first_label <span class="op">=</span> y_train.iloc[<span class="dv">0</span>]</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>first_image <span class="op">=</span> X_train.iloc[<span class="dv">0</span>].values.reshape(<span class="dv">16</span>, <span class="dv">16</span>)</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>plt.imshow(first_image, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f'Digit: </span><span class="sc">{</span>first_label<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                   0
0  6.0000 -1.0000 -1.0000 -1.0000 -1.0000 -1.0000...
1  5.0000 -1.0000 -1.0000 -1.0000 -0.8130 -0.6710...
2  4.0000 -1.0000 -1.0000 -1.0000 -1.0000 -1.0000...
3  7.0000 -1.0000 -1.0000 -1.0000 -1.0000 -1.0000...
4  3.0000 -1.0000 -1.0000 -1.0000 -1.0000 -1.0000...

Columns: [0]
Training: 7291 samples, 256 features
Test: 2007 samples, 256 features</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Assignment1_Mehreen_files/figure-html/cell-11-output-2.png" width="389" height="409" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ol start="2" type="a">
<li>The following code imports the kNN classification function from scikit-learn as well as an accuracy function, trains a kNN classifier, and tests its accuracy on hypothetical training and testing data:</li>
</ol>
<div id="ae8273e1" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Train KNN model</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train, y_train)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on training data</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>y_pred_train <span class="op">=</span> knn.predict(X_train)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>train_accuracy <span class="op">=</span> accuracy_score(y_train, y_pred_train)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Training Accuracy: </span><span class="sc">{</span>train_accuracy<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on test data (using your test variables)</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>y_pred_test <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>test_accuracy <span class="op">=</span> accuracy_score(y_test, y_pred_test)</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Test Accuracy: </span><span class="sc">{</span>test_accuracy<span class="sc">:.4f}</span><span class="ss">'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training Accuracy: 0.9807
Test Accuracy: 0.9432</code></pre>
</div>
</div>
<div id="86cd439d" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate k values (logarithmic scale like Figure 2.17)</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>k_values <span class="op">=</span> np.unique(np.logspace(<span class="dv">0</span>, np.log10(<span class="dv">300</span>), <span class="dv">20</span>).astype(<span class="bu">int</span>))</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing k values: </span><span class="sc">{</span>k_values<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>train_accuracies, test_accuracies <span class="op">=</span> [], []</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_values:</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train KNN</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span>k)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    knn.fit(X_train, y_train)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training accuracy</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    y_pred_train <span class="op">=</span> knn.predict(X_train)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    train_acc <span class="op">=</span> accuracy_score(y_train, y_pred_train)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    train_accuracies.append(train_acc)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Testing accuracy</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    y_pred_test <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    test_acc <span class="op">=</span> accuracy_score(y_test, y_pred_test)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    test_accuracies.append(test_acc)</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"k=</span><span class="sc">{</span>k<span class="sc">:3d}</span><span class="ss">: Train Acc=</span><span class="sc">{</span>train_acc<span class="sc">:.4f}</span><span class="ss">, Test Acc=</span><span class="sc">{</span>test_acc<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot results</span></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>plt.semilogx(k_values, train_accuracies, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Training Accuracy'</span>)</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>plt.semilogx(k_values, test_accuracies, <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Test Accuracy'</span>)</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Neighbors (k)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Bias-Variance Trade-off in KNN'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>plt.xlim(<span class="dv">1</span>, <span class="dv">300</span>)</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="fl">0.7</span>, <span class="fl">1.02</span>)</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Find optimal k</span></span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a>optimal_idx <span class="op">=</span> np.argmax(test_accuracies)</span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>optimal_k <span class="op">=</span> k_values[optimal_idx]</span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Optimal k: </span><span class="sc">{</span>optimal_k<span class="sc">}</span><span class="ss"> with test accuracy: </span><span class="sc">{</span>test_accuracies[optimal_idx]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for U-shaped curve</span></span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> test_accuracies[<span class="dv">0</span>] <span class="op">&gt;</span> test_accuracies[<span class="dv">1</span>]:</span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"✓ U-shaped curve observed: Test error decreases then increases with k"</span>)</span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"✗ No clear U-shaped curve observed"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Testing k values: [  1   2   3   4   6   8  11  14  20  27  36  49  66  90 121 164 222 300]
k=  1: Train Acc=1.0000, Test Acc=0.9437
k=  2: Train Acc=0.9837, Test Acc=0.9412
k=  3: Train Acc=0.9867, Test Acc=0.9447
k=  4: Train Acc=0.9807, Test Acc=0.9432
k=  6: Train Acc=0.9759, Test Acc=0.9387
k=  8: Train Acc=0.9724, Test Acc=0.9407
k= 11: Train Acc=0.9690, Test Acc=0.9312
k= 14: Train Acc=0.9653, Test Acc=0.9292
k= 20: Train Acc=0.9530, Test Acc=0.9178
k= 27: Train Acc=0.9461, Test Acc=0.9153
k= 36: Train Acc=0.9392, Test Acc=0.9093
k= 49: Train Acc=0.9301, Test Acc=0.8969
k= 66: Train Acc=0.9196, Test Acc=0.8834
k= 90: Train Acc=0.9082, Test Acc=0.8675
k=121: Train Acc=0.8926, Test Acc=0.8560
k=164: Train Acc=0.8759, Test Acc=0.8406
k=222: Train Acc=0.8563, Test Acc=0.8201
k=300: Train Acc=0.8360, Test Acc=0.7997</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Assignment1_Mehreen_files/figure-html/cell-13-output-2.png" width="600" height="456" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Optimal k: 3 with test accuracy: 0.9447
✓ U-shaped curve observed: Test error decreases then increases with k</code></pre>
</div>
</div>
<ol start="3" type="a">
<li>Modify the code above to plot the training and test accuracy as a function of 1/k (the inverse of k), similar to Figure 2.17 in the ISL book. Comment on the results, relating them to the bias-variance trade-off.</li>
</ol>
<div id="33f78bc2" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate k values (1 to 300, with more points at small k for detail)</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>k_values <span class="op">=</span> k_values <span class="op">=</span> np.unique(np.logspace(<span class="dv">0</span>, np.log10(<span class="dv">300</span>), <span class="dv">20</span>).astype(<span class="bu">int</span>))</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing k values: </span><span class="sc">{</span>k_values<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>train_acc, test_acc <span class="op">=</span> [], []</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_values:</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span>k).fit(X_train, y_train)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    train_acc.append(knn.score(X_train, y_train))</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    test_acc.append(knn.score(X_test, y_test))</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate 1/k (inverse relationship)</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>inverse_k <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> k_values</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot with 1/k on x-axis (as in ISL book)</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">10</span>))</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 1: Traditional k on x-axis</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>plt.plot(k_values, train_acc, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Training'</span>)</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>plt.plot(k_values, test_acc, <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Test'</span>)</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Neighbors (k)'</span>)</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Accuracy vs k'</span>)</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>plt.tight_layout(rect<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.96</span>])</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 2: 1/k on x-axis (like ISL Figure 2.17)</span></span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>plt.plot(inverse_k, train_acc, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Training'</span>)</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>plt.plot(inverse_k, test_acc, <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Test'</span>)</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'1/k (Model Flexibility →)'</span>)</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Accuracy vs 1/k (Flexibility)'</span>)</span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_xaxis()  <span class="co"># Reverse so 1/k increases left to right</span></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Testing k values: [  1   2   3   4   6   8  11  14  20  27  36  49  66  90 121 164 222 300]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Assignment1_Mehreen_files/figure-html/cell-14-output-2.png" width="758" height="950" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This code shows you two views of the same phenomenon:</p>
<p>Left plot: How accuracy changes as we add more neighbors (smaller k = more flexible, larger k = less flexible) Right plot: How accuracy changes as model flexibility changes (1/k is a proxy for flexibility - higher 1/k = more flexible model) The right plot mimics the ISL book’s Figure 2.17 by using 1/k on the x-axis to represent model flexibility, illustrating the bias-variance trade-off in KNN classification.</p>
<p>As k decreases (more flexible model), training accuracy increases, but test accuracy initially increases then decreases, showing overfitting. As k increases (less flexible), both accuracies converge, indicating underfitting. The optimal k balances bias and variance for best generalization.</p>
<ol start="3" type="a">
<li>Introduce some noise in the training and testing labels for both the training and testing data. You can do this by using np.random.choice to sample from the range of indices of each of the training and test set to determine which labels will be changed, and np.random.choice again to pick the new label. After making this modification, repeat problem (b). How did adding label noise impact the shape of the testing and training error versus 1/k curves?</li>
</ol>
<div id="2938d951" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Add label noise (20% of labels)</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_noise(y, noise_frac<span class="op">=</span><span class="fl">0.2</span>):</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    y_noisy <span class="op">=</span> y.copy()</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    n_noise <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(y) <span class="op">*</span> noise_frac)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    noise_indices <span class="op">=</span> np.random.choice(<span class="bu">len</span>(y), n_noise, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> noise_indices:</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>        current_label <span class="op">=</span> y[idx]</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Choose new label from all labels except current one</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>        possible_labels <span class="op">=</span> [l <span class="cf">for</span> l <span class="kw">in</span> np.unique(y) <span class="cf">if</span> l <span class="op">!=</span> current_label]</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>        y_noisy[idx] <span class="op">=</span> np.random.choice(possible_labels)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y_noisy</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Create noisy labels</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>y_train_noisy <span class="op">=</span> add_noise(y_train, <span class="fl">0.2</span>)</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>y_test_noisy <span class="op">=</span> add_noise(y_test, <span class="fl">0.2</span>)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Test k values</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>k_values <span class="op">=</span> np.concatenate([np.arange(<span class="dv">1</span>, <span class="dv">10</span>), np.arange(<span class="dv">10</span>, <span class="dv">101</span>, <span class="dv">10</span>), np.arange(<span class="dv">150</span>, <span class="dv">301</span>, <span class="dv">50</span>)])</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Train with original and noisy labels</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>train_acc_orig, test_acc_orig <span class="op">=</span> [], []</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>train_acc_noisy, test_acc_noisy <span class="op">=</span> [], []</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_values:</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Original labels</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>    knn_orig <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span>k).fit(X_train, y_train)</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>    train_acc_orig.append(knn_orig.score(X_train, y_train))</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>    test_acc_orig.append(knn_orig.score(X_test, y_test))</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Noisy labels</span></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>    knn_noisy <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span>k).fit(X_train, y_train_noisy)</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>    train_acc_noisy.append(knn_noisy.score(X_train, y_train_noisy))</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>    test_acc_noisy.append(knn_noisy.score(X_test, y_test_noisy))</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Calculate errors</span></span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>train_err_orig <span class="op">=</span> [<span class="dv">1</span> <span class="op">-</span> acc <span class="cf">for</span> acc <span class="kw">in</span> train_acc_orig]</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>test_err_orig <span class="op">=</span> [<span class="dv">1</span> <span class="op">-</span> acc <span class="cf">for</span> acc <span class="kw">in</span> test_acc_orig]</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>train_err_noisy <span class="op">=</span> [<span class="dv">1</span> <span class="op">-</span> acc <span class="cf">for</span> acc <span class="kw">in</span> train_acc_noisy]</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>test_err_noisy <span class="op">=</span> [<span class="dv">1</span> <span class="op">-</span> acc <span class="cf">for</span> acc <span class="kw">in</span> test_acc_noisy]</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Plot comparison</span></span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">10</span>))</span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 1: Test error comparison</span></span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a>inverse_k <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>k_values</span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>plt.plot(inverse_k, test_err_orig, <span class="st">'b-'</span>, label<span class="op">=</span><span class="st">'Original Labels'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>plt.plot(inverse_k, test_err_noisy, <span class="st">'r-'</span>, label<span class="op">=</span><span class="st">'Noisy Labels (20%)'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_xaxis()</span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'1/k (Flexibility →)'</span>)</span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Test Error'</span>)</span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Test Error: Impact of Label Noise'</span>)</span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a>plt.tight_layout(rect<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.96</span>])</span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 2: Train vs Test error with noise</span></span>
<span id="cb27-61"><a href="#cb27-61" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb27-62"><a href="#cb27-62" aria-hidden="true" tabindex="-1"></a>plt.plot(inverse_k, train_err_noisy, <span class="st">'b--'</span>, label<span class="op">=</span><span class="st">'Train Error (Noisy)'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb27-63"><a href="#cb27-63" aria-hidden="true" tabindex="-1"></a>plt.plot(inverse_k, test_err_noisy, <span class="st">'r-'</span>, label<span class="op">=</span><span class="st">'Test Error (Noisy)'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb27-64"><a href="#cb27-64" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_xaxis()</span>
<span id="cb27-65"><a href="#cb27-65" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'1/k (Flexibility →)'</span>)</span>
<span id="cb27-66"><a href="#cb27-66" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Error'</span>)</span>
<span id="cb27-67"><a href="#cb27-67" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Train vs Test Error with Label Noise'</span>)</span>
<span id="cb27-68"><a href="#cb27-68" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb27-69"><a href="#cb27-69" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb27-70"><a href="#cb27-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-71"><a href="#cb27-71" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb27-72"><a href="#cb27-72" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb27-73"><a href="#cb27-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-74"><a href="#cb27-74" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. Analyze impact</span></span>
<span id="cb27-75"><a href="#cb27-75" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"IMPACT OF LABEL NOISE:"</span>)</span>
<span id="cb27-76"><a href="#cb27-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">40</span>)</span>
<span id="cb27-77"><a href="#cb27-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-78"><a href="#cb27-78" aria-hidden="true" tabindex="-1"></a><span class="co"># Find optimal k for each</span></span>
<span id="cb27-79"><a href="#cb27-79" aria-hidden="true" tabindex="-1"></a>optimal_k_orig <span class="op">=</span> k_values[np.argmin(test_err_orig)]</span>
<span id="cb27-80"><a href="#cb27-80" aria-hidden="true" tabindex="-1"></a>optimal_k_noisy <span class="op">=</span> k_values[np.argmin(test_err_noisy)]</span>
<span id="cb27-81"><a href="#cb27-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-82"><a href="#cb27-82" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Without noise: Optimal k = </span><span class="sc">{</span>optimal_k_orig<span class="sc">}</span><span class="ss">, Min test error = </span><span class="sc">{</span><span class="bu">min</span>(test_err_orig)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb27-83"><a href="#cb27-83" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"With noise:    Optimal k = </span><span class="sc">{</span>optimal_k_noisy<span class="sc">}</span><span class="ss">, Min test error = </span><span class="sc">{</span><span class="bu">min</span>(test_err_noisy)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb27-84"><a href="#cb27-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-85"><a href="#cb27-85" aria-hidden="true" tabindex="-1"></a><span class="co"># Error increase</span></span>
<span id="cb27-86"><a href="#cb27-86" aria-hidden="true" tabindex="-1"></a>error_increase <span class="op">=</span> <span class="bu">min</span>(test_err_noisy) <span class="op">-</span> <span class="bu">min</span>(test_err_orig)</span>
<span id="cb27-87"><a href="#cb27-87" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Test error increased by: </span><span class="sc">{</span>error_increase<span class="sc">:.4f}</span><span class="ss"> (+</span><span class="sc">{</span>error_increase<span class="op">/</span><span class="bu">min</span>(test_err_orig)<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%)"</span>)</span>
<span id="cb27-88"><a href="#cb27-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-89"><a href="#cb27-89" aria-hidden="true" tabindex="-1"></a><span class="co"># Check U-shape preservation</span></span>
<span id="cb27-90"><a href="#cb27-90" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">U-shape preserved with noise: </span><span class="sc">{</span><span class="st">'Yes'</span> <span class="cf">if</span> test_err_noisy[<span class="dv">0</span>] <span class="op">&gt;</span> <span class="bu">min</span>(test_err_noisy) <span class="kw">and</span> test_err_noisy[<span class="op">-</span><span class="dv">1</span>] <span class="op">&gt;</span> <span class="bu">min</span>(test_err_noisy) <span class="cf">else</span> <span class="st">'No'</span><span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Assignment1_Mehreen_files/figure-html/cell-15-output-1.png" width="758" height="950" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>IMPACT OF LABEL NOISE:
========================================
Without noise: Optimal k = 3, Min test error = 0.0553
With noise:    Optimal k = 10, Min test error = 0.2486

Test error increased by: 0.1933 (+349.5%)

U-shape preserved with noise: Yes</code></pre>
</div>
</div>
<p>Label noise acts like adding variance to the model, making it harder to fit the true underlying patterns. As a result, we observe:</p>
<ol type="1">
<li><p>Increased Test Error: The minimum test error increases significantly with label noise, indicating worse generalization performance.</p></li>
<li><p>Shifted Optimal k: The optimal k value may shift, often favoring larger k values to smooth out the noise.</p></li>
<li><p>U-Shape Preservation: The U-shaped curve of test error vs.&nbsp;1/k is generally preserved, but the curve may be less pronounced, indicating that the model struggles more with noisy labels across all k values.</p></li>
</ol>
<p>Overall, label noise degrades model performance and highlights the importance of clean data for effective learning.</p>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>